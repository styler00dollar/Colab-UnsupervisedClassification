{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Colab-UnsupervisedClassification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRhzDn1IObLk"
      },
      "source": [
        "# Colab-UnsupervisedClassification\r\n",
        "\r\n",
        "Original repo: [ardamavi/Unsupervised-Classification-with-Autoencoder](https://github.com/ardamavi/Unsupervised-Classification-with-Autoencoder)\r\n",
        "\r\n",
        "Original colab: [here](https://colab.research.google.com/github/ardamavi/Unsupervised-Classification-with-Autoencoder/blob/master/Unsupervised%20Classification%20With%20Autoencoder.ipynb)\r\n",
        "\r\n",
        "My fork: []()\r\n",
        "\r\n",
        "Contains a few improvements, like fewer boxes, OpenCV, robuster data loading (jpg/png glob) and tqdm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmAp6M8YKySb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMX5UupjK2Rz",
        "cellView": "form"
      },
      "source": [
        "#@title install\r\n",
        "!git clone https://github.com/ardamavi/Unsupervised-Classification-with-Autoencoder\r\n",
        "#!pip install scipy==1.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVHfBLjoO3fJ"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zYqdpu0KLIo",
        "cellView": "form"
      },
      "source": [
        "#@title example dog/cat dataset\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from os import listdir\r\n",
        "from scipy.misc import imread, imresize\r\n",
        "from keras.utils import to_categorical\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import keras\r\n",
        "import numpy as np\r\n",
        "from keras.datasets import mnist\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "def get_img(data_path):\r\n",
        "    # Getting image array from path:\r\n",
        "    img_size = 64 #@param {type:\"number\"}\r\n",
        "    #img = imread(data_path)\r\n",
        "    #img = imresize(img, (img_size, img_size, 3))\r\n",
        "\r\n",
        "    img = cv2.imread(data_path)\r\n",
        "    img = cv2.resize(img, (img_size, img_size))\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "\r\n",
        "    return img\r\n",
        "\r\n",
        "def get_dataset(dataset_path='/content/Unsupervised-Classification-with-Autoencoder/Examples/Dog-Cat/Data/Train_Data/'):\r\n",
        "    # Getting all data from data path:\r\n",
        "    try:\r\n",
        "        X = np.load('Data/npy_train_data/X.npy')\r\n",
        "        Y = np.load('Data/npy_train_data/Y.npy')\r\n",
        "    except:\r\n",
        "        labels = listdir(dataset_path) # Geting labels\r\n",
        "        X = []\r\n",
        "        Y = []\r\n",
        "        for i, label in enumerate(labels):\r\n",
        "            datas_path = dataset_path+'/'+label\r\n",
        "            for data in listdir(datas_path):\r\n",
        "                img = get_img(datas_path+'/'+data)\r\n",
        "                X.append(img)\r\n",
        "                Y.append(i)\r\n",
        "        # Create dateset:\r\n",
        "        X = np.array(X).astype('float32')/255.\r\n",
        "        Y = np.array(Y).astype('float32')\r\n",
        "        Y = to_categorical(Y, 2)\r\n",
        "        if not os.path.exists('Data/npy_train_data/'):\r\n",
        "            os.makedirs('Data/npy_train_data/')\r\n",
        "        np.save('Data/npy_train_data/X.npy', X)\r\n",
        "        np.save('Data/npy_train_data/Y.npy', Y)\r\n",
        "    X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\r\n",
        "    return X, X_test, Y, Y_test\r\n",
        "\r\n",
        "# Getting Dataset:\r\n",
        "X_train, X_test, Y_train, Y_test = get_dataset()\r\n",
        "\r\n",
        "# Checkpoints:\r\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\r\n",
        "checkpoints = []\r\n",
        "#checkpoints.append(TensorBoard(log_dir='/Checkpoints/logs'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8hgn1YLPFod"
      },
      "source": [
        "Or use your own data and amount of classes. Example structure is [here](https://github.com/ardamavi/Unsupervised-Classification-with-Autoencoder/tree/master/Examples/Dog-Cat/Data/Train_Data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "qhh5-mr6P0ap"
      },
      "source": [
        "#@title Mount Google Drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "print('Google Drive connected.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zcRyxuoYQHUl"
      },
      "source": [
        "#@title copy/extract data\r\n",
        "!cp /content/drive/MyDrive/classification.7z /content/dataset.7z\r\n",
        "%cd /content/\r\n",
        "!7z x /content/dataset.7z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH6NruuMQ1rg",
        "cellView": "form"
      },
      "source": [
        "#@title example own data\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from os import listdir\r\n",
        "from keras.utils import to_categorical\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import keras\r\n",
        "import numpy as np\r\n",
        "from keras.datasets import mnist\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tqdm import tqdm\r\n",
        "import glob\r\n",
        "import cv2\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "dataset_path = '/content/images/' #@param {type:\"string\"}\r\n",
        "num_classes = 2 #@param {type:\"number\"}\r\n",
        "\r\n",
        "def get_img(data_path):\r\n",
        "    # Getting image array from path:\r\n",
        "    img_size = 64 #@param {type:\"number\"}\r\n",
        "    #img = imread(data_path)\r\n",
        "    #img = imresize(img, (img_size, img_size, 3))\r\n",
        "\r\n",
        "    img = cv2.imread(data_path)\r\n",
        "    img = cv2.resize(img, (img_size, img_size))\r\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "\r\n",
        "    return img\r\n",
        "\r\n",
        "def get_dataset(dataset_path=dataset_path):\r\n",
        "    # Getting all data from data path:\r\n",
        "    try:\r\n",
        "        X = np.load('Data/npy_train_data/X.npy')\r\n",
        "        Y = np.load('Data/npy_train_data/Y.npy')\r\n",
        "    except:\r\n",
        "        labels = listdir(dataset_path) # Geting labels\r\n",
        "        X = []\r\n",
        "        Y = []\r\n",
        "        for i, label in enumerate(labels):\r\n",
        "            datas_path = dataset_path+'/'+label\r\n",
        "            #for data in listdir(datas_path):\r\n",
        "            #print(\"datas_path\")\r\n",
        "            #print(datas_path)\r\n",
        "            files = glob.glob(datas_path + '/**/*.png', recursive=True)\r\n",
        "            files_jpg = glob.glob(datas_path + '/**/*.jpg', recursive=True)\r\n",
        "            files.extend(files_jpg)\r\n",
        "            for data in tqdm(files):\r\n",
        "\r\n",
        "                img = get_img(data)\r\n",
        "                X.append(img)\r\n",
        "                Y.append(i)\r\n",
        "        # Create dateset:\r\n",
        "        X = np.array(X).astype('float32')/255.\r\n",
        "        Y = np.array(Y).astype('float32')\r\n",
        "        Y = to_categorical(Y, num_classes)\r\n",
        "        if not os.path.exists('Data/npy_train_data/'):\r\n",
        "            os.makedirs('Data/npy_train_data/')\r\n",
        "        np.save('Data/npy_train_data/X.npy', X)\r\n",
        "        np.save('Data/npy_train_data/Y.npy', Y)\r\n",
        "    X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\r\n",
        "    return X, X_test, Y, Y_test\r\n",
        "\r\n",
        "# Getting Dataset:\r\n",
        "X_train, X_test, Y_train, Y_test = get_dataset()\r\n",
        "\r\n",
        "# Checkpoints:\r\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\r\n",
        "checkpoints = []\r\n",
        "#checkpoints.append(TensorBoard(log_dir='/Checkpoints/logs'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSpMEcPSPBI1"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TQaTm4p_J8pC",
        "cellView": "form"
      },
      "source": [
        "#@title display info\n",
        "# About Dataset:\n",
        "img_size = X_train.shape[1] # 64\n",
        "print('Training shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'sample,',X_train.shape[1] ,'x',X_train.shape[2] ,'size RGB image.\\n')\n",
        "print('Test shape:', X_test.shape)\n",
        "print(X_test.shape[0], 'sample,',X_test.shape[1] ,'x',X_test.shape[2] ,'size RGB image.\\n')\n",
        "\n",
        "print('Examples:')\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n+1):\n",
        "    # Display some data:\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(X_train[i])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# Deep Learning Model:\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "input_img = Input(shape=(64, 64, 3))\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='rmsprop', loss='mse')\n",
        "\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "IyvIcIgmJ8pE",
        "cellView": "form"
      },
      "source": [
        "#@title train\n",
        "# Creates live data:\n",
        "# For better yield. The duration of the training is extended.\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "generated_data = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, rotation_range=0,  width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True, vertical_flip = False)\n",
        "generated_data.fit(X_train)\n",
        "\n",
        "epochs = 100 #@param {type:\"number\"}\n",
        "batch_size = 16 #@param {type:\"number\"}\n",
        "\n",
        "#autoencoder.fit_generator(generated_data.flow(X_train, X_train, batch_size=batch_size), steps_per_epoch=X.shape[0], epochs=epochs, validation_data=(X_test, X_test), callbacks=checkpoints)\n",
        "\n",
        "# Training Model:\n",
        "autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, X_test), shuffle=True, callbacks=checkpoints)\n",
        "\n",
        "decoded_imgs = autoencoder.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38aeS_2DJ8pF",
        "cellView": "form"
      },
      "source": [
        "#@title plot images\n",
        "n = 10 #@param {type:\"number\"}\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n+1):\n",
        "    # Display original:\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(X_test[i])\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction:\n",
        "    ax = plt.subplot(2, n, i+n)\n",
        "    plt.imshow(decoded_imgs[i])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gzZIAapPJ8pF",
        "cellView": "form"
      },
      "source": [
        "#@title model\n",
        "# Describe the number of classes:\n",
        "num_class = 2 #@param {type:\"number\"}\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# Custom classifier function:\n",
        "def classifier_func(x):\n",
        "    return x-x+K.one_hot(K.argmax(x, axis=1), num_classes=num_class)\n",
        "\n",
        "# Deep Learning Model:\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense, Activation, Lambda, Flatten, concatenate, Reshape\n",
        "from keras.models import Model\n",
        "\n",
        "input_img = Input(shape=(64, 64, 3))\n",
        "\n",
        "layer_1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "layer_1 = MaxPooling2D((2, 2))(layer_1)\n",
        "\n",
        "layer_2 = Conv2D(64, (3, 3), activation='relu', padding='same')(layer_1)\n",
        "layer_2 = MaxPooling2D((2, 2))(layer_2)\n",
        "\n",
        "layer_3 = Conv2D(64, (3, 3), activation='relu', padding='same')(layer_2)\n",
        "layer_3 = MaxPooling2D((2, 2))(layer_3)\n",
        "\n",
        "flat_1 = Flatten()(layer_3)\n",
        "\n",
        "fc_1 = Dense(256)(flat_1)\n",
        "fc_1 = Activation('relu')(fc_1)\n",
        "\n",
        "fc_2 = Dense(128)(fc_1)\n",
        "fc_2 = Activation('relu')(fc_2)\n",
        "\n",
        "fc_3 = Dense(num_class)(fc_2)\n",
        "act_class = Lambda(classifier_func, output_shape=(num_class,))(fc_3)\n",
        "\n",
        "# Merge Layers:\n",
        "\n",
        "merge_1 = concatenate([act_class, fc_2])\n",
        "\n",
        "#Decoder:\n",
        "fc_4 = Dense(256)(merge_1)\n",
        "fc_4 = Activation('relu')(fc_4)\n",
        "\n",
        "fc_5 = Dense(4096)(fc_4)\n",
        "fc_5 = Activation('relu')(fc_5)\n",
        "\n",
        "reshape_1 = Reshape((8, 8, 64))(fc_5)\n",
        "\n",
        "layer_4 = UpSampling2D((2, 2))(reshape_1)\n",
        "layer_4 = Conv2D(64, (3, 3), activation='relu', padding='same')(layer_4)\n",
        "\n",
        "layer_5 = UpSampling2D((2, 2))(layer_4)\n",
        "layer_5 = Conv2D(64, (3, 3), activation='relu', padding='same')(layer_5)\n",
        "\n",
        "layer_6 = UpSampling2D((2, 2))(layer_5)\n",
        "layer_6 = Conv2D(32, (3, 3), activation='relu', padding='same')(layer_6)\n",
        "\n",
        "layer_7 = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(layer_6)\n",
        "\n",
        "autoencoder = Model(input_img, layer_7)\n",
        "autoencoder.compile(optimizer='rmsprop', loss='mse')\n",
        "\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Cl85-fT7J8pG",
        "cellView": "form"
      },
      "source": [
        "#@title train\n",
        "# Creates live data:\n",
        "# For better yield. The duration of the training is extended.\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "generated_data = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, rotation_range=0,  width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True, vertical_flip = False)\n",
        "generated_data.fit(X_train)\n",
        "\n",
        "#autoencoder.fit_generator(generated_data.flow(X_train, X_train, batch_size=batch_size), steps_per_epoch=X.shape[0], epochs=epochs, validation_data=(X_test, X_test), callbacks=checkpoints)\n",
        "\n",
        "# Training Model:\n",
        "epochs = 100 #@param {type:\"number\"}\n",
        "batch_size = 16 #@param {type:\"number\"}\n",
        "autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, X_test), shuffle=True, callbacks=checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "99JkbfQfJ8pH",
        "cellView": "form"
      },
      "source": [
        "#@title plot\n",
        "decoded_imgs = autoencoder.predict(X_test)\n",
        "n = 10 #@param {type:\"number\"}\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(X_test[i])\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i])\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# Split autoencoder:\n",
        "encoder = Model(input_img, act_class)\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "0dUqyV2lJ8pI",
        "cellView": "form"
      },
      "source": [
        "#@title show examples (edit cat_dog() if you have other classes)\n",
        "encode = encoder.predict(X_train)\n",
        "\n",
        "class_dict = np.zeros((num_class, num_class))\n",
        "for i, sample in enumerate(Y_train):\n",
        "    class_dict[np.argmax(encode[i], axis=0)][np.argmax(sample)] += 1\n",
        "    \n",
        "print(class_dict)\n",
        "    \n",
        "neuron_class = np.zeros((num_class))\n",
        "for i in range(num_class):\n",
        "    neuron_class[i] = np.argmax(class_dict[i], axis=0)\n",
        "\n",
        "print(neuron_class)\n",
        "\n",
        "# Getting class as string:\n",
        "def cat_dog(model_output):\n",
        "    if model_output == 0:\n",
        "        return \"Cat\"\n",
        "    else:\n",
        "        return \"Dog\"\n",
        "\n",
        "encode = encoder.predict(X_test)\n",
        "\n",
        "predicted = np.argmax(encode, axis=1)\n",
        "for i, sample in enumerate(predicted):\n",
        "    predicted[i] = neuron_class[predicted[i]]\n",
        "\n",
        "comparison = predicted == np.argmax(Y_test, axis=1)\n",
        "loss = 1 - np.sum(comparison.astype(int))/Y_test.shape[0]\n",
        "\n",
        "print('Loss:', loss)\n",
        "print('Examples:')\n",
        "for i in range(10):\n",
        "    plt.imshow(X_test[i])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    neuron = np.argmax(encode[i], axis=0)\n",
        "    print('Class:',  cat_dog(np.argmax(Y_test[i], axis=0)), '- Model\\'s Output Class:', cat_dog(neuron_class[neuron]),'\\n'*2,'-'*40)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}